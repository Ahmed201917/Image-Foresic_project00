{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2048184,
          "sourceType": "datasetVersion",
          "datasetId": 1226991
        }
      ],
      "dockerImageVersionId": 30684,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"divg07/casia-20-image-tampering-detection-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lku-LI_iWO7k",
        "outputId": "d7d9b5e1-01bf-4a84-c4a6-9800bf3f8143"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/divg07/casia-20-image-tampering-detection-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.56G/2.56G [00:48<00:00, 56.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/divg07/casia-20-image-tampering-detection-dataset/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /root/.cache/kagglehub/datasets/divg07/casia-20-image-tampering-detection-dataset/versions/1 /content/"
      ],
      "metadata": {
        "id": "1mvVmg5KW0kD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import (Dense, Dropout, Flatten, Conv2D, MaxPool2D,\n",
        "                                   BatchNormalization, GlobalAveragePooling2D, Input)\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import gc"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-12-21T17:13:23.960511Z",
          "iopub.execute_input": "2024-12-21T17:13:23.960809Z",
          "iopub.status.idle": "2024-12-21T17:13:36.928816Z",
          "shell.execute_reply.started": "2024-12-21T17:13:23.960769Z",
          "shell.execute_reply": "2024-12-21T17:13:36.928152Z"
        },
        "trusted": true,
        "id": "uE8_K8IaOu_H"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# Set memory growth for GPU if available\n",
        "try:\n",
        "    physical_devices = tf.config.list_physical_devices('GPU')\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "p4xyx0_4hcaD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_ela_image(path, quality):\n",
        "    \"\"\"Enhanced ELA implementation with error handling and cleanup\"\"\"\n",
        "    temp_filename = 'temp_file_name.jpg'\n",
        "    try:\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        image.save(temp_filename, 'JPEG', quality=quality)\n",
        "        temp_image = Image.open(temp_filename)\n",
        "        ela_image = ImageChops.difference(image, temp_image)\n",
        "\n",
        "        # Calculate scaling factor\n",
        "        extrema = ela_image.getextrema()\n",
        "        max_diff = max([ex[1] for ex in extrema])\n",
        "        max_diff = max(1, max_diff)  # Avoid division by zero\n",
        "        scale = 255.0 / max_diff\n",
        "\n",
        "        # Enhance and normalize\n",
        "        ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
        "        return ela_image\n",
        "\n",
        "    finally:\n",
        "        # Cleanup temp file\n",
        "        if os.path.exists(temp_filename):\n",
        "            os.remove(temp_filename)"
      ],
      "metadata": {
        "id": "Pwy-IGoAhd0J"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_image(image_path, image_size=(128, 128)):  # Reduced image size\n",
        "    \"\"\"Memory-efficient image preparation\"\"\"\n",
        "    try:\n",
        "        ela_img = convert_to_ela_image(image_path, 90)\n",
        "        ela_img = ela_img.resize(image_size)\n",
        "        ela_array = np.array(ela_img)\n",
        "\n",
        "        # Clear PIL Image objects\n",
        "        ela_img.close()\n",
        "        del ela_img\n",
        "\n",
        "        return ela_array / 255.0\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image {image_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    \"\"\"Custom data generator class\"\"\"\n",
        "    def __init__(self, authentic_path, tampered_path, batch_size=32, is_training=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.is_training = is_training\n",
        "        self.authentic_files = []\n",
        "        self.tampered_files = []\n",
        "\n",
        "        # Collect file paths\n",
        "        for root, _, files in os.walk(authentic_path):\n",
        "            self.authentic_files.extend([os.path.join(root, f) for f in files\n",
        "                                      if f.lower().endswith(('jpg', 'jpeg', 'png'))])\n",
        "\n",
        "        for root, _, files in os.walk(tampered_path):\n",
        "            self.tampered_files.extend([os.path.join(root, f) for f in files\n",
        "                                      if f.lower().endswith(('jpg', 'jpeg', 'png'))])\n",
        "\n",
        "        # Shuffle files\n",
        "        np.random.shuffle(self.authentic_files)\n",
        "        np.random.shuffle(self.tampered_files)\n",
        "\n",
        "        # Limit dataset size for memory efficiency\n",
        "        max_samples = 2000 if self.is_training else 500\n",
        "        self.authentic_files = self.authentic_files[:max_samples]\n",
        "        self.tampered_files = self.tampered_files[:max_samples]\n",
        "\n",
        "        self.indexes = np.arange(len(self.authentic_files) + len(self.tampered_files))\n",
        "        np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.indexes) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        X_batch = []\n",
        "        y_batch = []\n",
        "\n",
        "        for idx in indexes:\n",
        "            if idx < len(self.authentic_files):\n",
        "                img = prepare_image(self.authentic_files[idx])\n",
        "                if img is not None:\n",
        "                    X_batch.append(img)\n",
        "                    y_batch.append(1)\n",
        "            else:\n",
        "                tampered_idx = idx - len(self.authentic_files)\n",
        "                img = prepare_image(self.tampered_files[tampered_idx])\n",
        "                if img is not None:\n",
        "                    X_batch.append(img)\n",
        "                    y_batch.append(0)\n",
        "\n",
        "        return np.array(X_batch), np.array(y_batch)\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indexes)"
      ],
      "metadata": {
        "id": "z7Z19-JKhgD4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_efficient_model(input_shape):\n",
        "    \"\"\"Memory-efficient model using MobileNetV2\"\"\"\n",
        "    base_model = MobileNetV2(weights='imagenet',\n",
        "                            include_top=False,\n",
        "                            input_shape=input_shape)\n",
        "\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.5),\n",
        "        Dense(2, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "1Tl64ZXmhh_F"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_gen, val_gen, model):\n",
        "    \"\"\"Training function with Colab-specific settings\"\"\"\n",
        "    callbacks = [\n",
        "        EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=5,\n",
        "            mode='max',\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.2,\n",
        "            patience=3,\n",
        "            min_lr=1e-6\n",
        "        ),\n",
        "        ModelCheckpoint(\n",
        "            'best_model.keras',\n",
        "            monitor='val_accuracy',\n",
        "            save_best_only=True,\n",
        "            mode='max'\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=val_gen,\n",
        "        epochs=20,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "XP1to8IVhjjP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Define paths for Colab\n",
        "    AUTHENTIC_PATH = '/content/1/CASIA2/Au'\n",
        "    TAMPERED_PATH = '/content/1/CASIA2/Tp'\n",
        "\n",
        "    # Parameters\n",
        "    BATCH_SIZE = 16  # Small batch size for memory efficiency\n",
        "    IMAGE_SIZE = (128, 128, 3)\n",
        "\n",
        "    # Verify paths exist\n",
        "    if not os.path.exists(AUTHENTIC_PATH) or not os.path.exists(TAMPERED_PATH):\n",
        "        raise ValueError(\"Dataset paths not found. Please check the paths.\")\n",
        "\n",
        "    # Create data generators\n",
        "    train_generator = DataGenerator(\n",
        "        AUTHENTIC_PATH,\n",
        "        TAMPERED_PATH,\n",
        "        BATCH_SIZE,\n",
        "        is_training=True\n",
        "    )\n",
        "\n",
        "    val_generator = DataGenerator(\n",
        "        AUTHENTIC_PATH,\n",
        "        TAMPERED_PATH,\n",
        "        BATCH_SIZE,\n",
        "        is_training=False\n",
        "    )\n",
        "\n",
        "    # Build and train model\n",
        "    model = build_efficient_model(IMAGE_SIZE)\n",
        "\n",
        "    history = train_model(\n",
        "        train_generator,\n",
        "        val_generator,\n",
        "        model\n",
        "    )\n",
        "\n",
        "    # Save final model\n",
        "    model.save('final_forgery_detection_model.h5')\n",
        "\n",
        "    # Clear memory\n",
        "    gc.collect()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u80izn03hlPv",
        "outputId": "2405e1a2-d91a-470e-d123-c75475685d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 232ms/step - accuracy: 0.6778 - loss: 0.7860 - val_accuracy: 0.8569 - val_loss: 0.3554 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 217ms/step - accuracy: 0.7958 - loss: 0.5591 - val_accuracy: 0.8760 - val_loss: 0.3289 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 214ms/step - accuracy: 0.8331 - loss: 0.4250 - val_accuracy: 0.8780 - val_loss: 0.3356 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 215ms/step - accuracy: 0.8348 - loss: 0.4121 - val_accuracy: 0.8891 - val_loss: 0.3212 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 213ms/step - accuracy: 0.8480 - loss: 0.3832 - val_accuracy: 0.8821 - val_loss: 0.2918 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 213ms/step - accuracy: 0.8625 - loss: 0.3458 - val_accuracy: 0.8992 - val_loss: 0.2747 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 214ms/step - accuracy: 0.8604 - loss: 0.3419 - val_accuracy: 0.9052 - val_loss: 0.2582 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 226ms/step - accuracy: 0.8803 - loss: 0.2979 - val_accuracy: 0.9042 - val_loss: 0.2501 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 265ms/step - accuracy: 0.8754 - loss: 0.3132 - val_accuracy: 0.8992 - val_loss: 0.2595 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 215ms/step - accuracy: 0.8800 - loss: 0.2920 - val_accuracy: 0.8942 - val_loss: 0.2649 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 215ms/step - accuracy: 0.8852 - loss: 0.2832 - val_accuracy: 0.9083 - val_loss: 0.2490 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 213ms/step - accuracy: 0.8954 - loss: 0.2587 - val_accuracy: 0.9052 - val_loss: 0.2485 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 213ms/step - accuracy: 0.8965 - loss: 0.2547 - val_accuracy: 0.9042 - val_loss: 0.2364 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 256ms/step - accuracy: 0.8952 - loss: 0.2655 - val_accuracy: 0.9143 - val_loss: 0.2352 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 213ms/step - accuracy: 0.9068 - loss: 0.2354 - val_accuracy: 0.9083 - val_loss: 0.2498 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 214ms/step - accuracy: 0.9066 - loss: 0.2381 - val_accuracy: 0.9183 - val_loss: 0.2231 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 212ms/step - accuracy: 0.9076 - loss: 0.2359 - val_accuracy: 0.9204 - val_loss: 0.2179 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 214ms/step - accuracy: 0.9024 - loss: 0.2299 - val_accuracy: 0.9194 - val_loss: 0.2282 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 211ms/step - accuracy: 0.8981 - loss: 0.2425 - val_accuracy: 0.9153 - val_loss: 0.2238 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m216/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 176ms/step - accuracy: 0.9107 - loss: 0.2282"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image, ImageChops, ImageEnhance\n",
        "import os\n",
        "\n",
        "def convert_to_ela_image(path, quality):\n",
        "    \"\"\"Convert image to ELA\"\"\"\n",
        "    temp_filename = 'temp_file_name.jpg'\n",
        "    try:\n",
        "        with Image.open(path) as image:\n",
        "            image = image.convert('RGB')\n",
        "            image.save(temp_filename, 'JPEG', quality=quality)\n",
        "\n",
        "            with Image.open(temp_filename) as temp_image:\n",
        "                ela_image = ImageChops.difference(image, temp_image)\n",
        "\n",
        "                extrema = ela_image.getextrema()\n",
        "                max_diff = max([ex[1] for ex in extrema])\n",
        "                max_diff = max(1, max_diff)\n",
        "                scale = 255.0 / max_diff\n",
        "\n",
        "                ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
        "                return ela_image\n",
        "    finally:\n",
        "        if os.path.exists(temp_filename):\n",
        "            os.remove(temp_filename)\n",
        "\n",
        "def predict_image(model_path, image_path):\n",
        "    \"\"\"Predict if image is authentic or tampered\"\"\"\n",
        "    # Load the model\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # Process image\n",
        "    ela_img = convert_to_ela_image(image_path, 90)\n",
        "    ela_img = ela_img.resize((128, 128))\n",
        "    ela_array = np.array(ela_img) / 255.0\n",
        "    ela_array = np.expand_dims(ela_array, axis=0)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = model.predict(ela_array, verbose=0)\n",
        "    authentic_prob = prediction[0][1] * 100\n",
        "    tampered_prob = prediction[0][0] * 100\n",
        "\n",
        "    # Print result\n",
        "    print(f\"\\nImage: {image_path}\")\n",
        "    print(f\"Result: {'AUTHENTIC' if authentic_prob > tampered_prob else 'TAMPERED'}\")\n",
        "    print(f\"Confidence: {max(authentic_prob, tampered_prob):.2f}%\")\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "nwntk3PROu_X"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your model and image paths\n",
        "predict_image('final_forgery_detection_model.h5', '/content/1/CASIA2/Tp/Tp_D_CRN_S_N_sec00041_sec00034_11251.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEj5rrGam8K4",
        "outputId": "736ab1f1-27c5-4652-b986-f0d7eebefaed"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image: /content/1/CASIA2/Tp/Tp_D_CRN_S_N_sec00041_sec00034_11251.jpg\n",
            "Result: TAMPERED\n",
            "Confidence: 96.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fb3Bfl3tq0tT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}